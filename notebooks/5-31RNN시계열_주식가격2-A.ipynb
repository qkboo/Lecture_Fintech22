{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK2WIdXPSnFc"
      },
      "source": [
        "# 주식 시계열 예측모델\n",
        "\n",
        "전통적으로 대부분의 머신러닝(ML) 모델은 일부 관찰(샘플/예제)을 입력 피쳐로 사용하지만 데이터에 시간 차원은 없다.\n",
        "\n",
        "시계열 예측 모형은 이전에 관측된 값을 기반으로 미래의 값을 예측할 수 있는 모형이다.\n",
        "\n",
        "시계열 예측은 비정형 데이터에서 널리 사용된다. 평균 및 표준 편차와 같은 통계적 특성이 시간이 지남에 따라 일정하지 않은 데이터를 비정형 데이터라고 한다.\n",
        "\n",
        "이러한 비정형 입력 데이터(해당 모델에 대한 입력으로 사용)를 일반적으로 시계열이라고 한다. 시계열의 예로는 시간 경과에 따른 온도, 주가, 주택 가격 등이 있다. 따라서 입력은 시간에 따라 연속적으로 나타나는 신호(시계열)이다.\n",
        "\n",
        "시계열은 시간에 따라 순차적으로 취하는 일련의 관측치이다.\n",
        "\n",
        "![image.png](https://i.imgur.com/IqyU5VO.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl58Zr-ZKjRE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "# import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "np.__version__, tf.__version__, keras.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6YXdz0QSnFj"
      },
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYZchMbRSnFk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p57M1lQoSnFk",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 폰트 목록에서 폰트 찾기\n",
        "for font in fm.fontManager.ttflist:\n",
        "    if 'Nanum' in font.name:\n",
        "        print(font.name, font.fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv9Ib6JRSnFl",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "%matplotlib inline\n",
        "\n",
        "# font_path = 'C:/Windows/Fonts/NanumGothic.ttf'\n",
        "# font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
        "font_path = \"/Users/qkboo/Library/Fonts/NanumGothic.otf\"\n",
        "fontname = fm.FontProperties(fname=font_path, size=18).get_name()  # 폰트 패밀리 이름!\n",
        "\n",
        "plt.rc('font', family=fontname)  #  'NanumGothic'\n",
        "# plt.rcParams[\"font.family\"] = fontname\n",
        "\n",
        "plt.rcParams['axes.unicode_minus'] = False #glypy 8722: Axes에 - 표시 안되는 것\n",
        "plt.title('한글 타이틀...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdgOvU8fSnFl"
      },
      "source": [
        "## 데이터\n",
        "\n",
        "구글 주가변동 데이터\n",
        " - http://finance.yahoo.com/quote/GOOG/history?ltr=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6v3HawqLSnFm"
      },
      "source": [
        "### 야후 파이낸스에서 주가 데이터 가져오기\n",
        "\n",
        "야후 파이낸스 덕분에 우리는 무료로 데이터를 얻을 수 있다. 다음 링크를 사용하여 테슬라의 주가 기록을 확인해보자.\n",
        "\n",
        "https://finance.yahoo.com/quote/TSLA/history?period1=1436486400&period2=1594339200&interval=1d&filter=history&frequency=1d\n",
        "\n",
        "![image.png](https://i.imgur.com/I37DVSw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maq8j00MSnFn"
      },
      "source": [
        "기간 동안의 주가를 다운로드 하면,\n",
        "\n",
        "![image.png](https://i.imgur.com/RH53Tha.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAUvvA7ISnFn"
      },
      "source": [
        "###  데이터 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhP3JGtdSnFo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFMap0HwSnFo"
      },
      "source": [
        "#### Colab에 Drive 마운트\n",
        "\n",
        "Google Drive에 `datasets` 폴더에 업로드 되었다고 가정."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNru1m6gSnFo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTjI-V4_SnFp"
      },
      "outputs": [],
      "source": [
        "! ls drive/MyDrive/datasets/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-IeBSuoSnFp"
      },
      "source": [
        "#### 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgdNbPCPSnFp"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv('drive/MyDrive/datasets/TSLA_2015-202207.csv')\n",
        "df = pd.read_csv('TSLA_2015-202207.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jai1YGaXSnFq"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJYgNS7SSnFq"
      },
      "source": [
        "일자별 종가(수정종가) 가격 그래프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hrhoc8wjSnFr"
      },
      "outputs": [],
      "source": [
        "df.plot(x='Date', y='Adj Close', rot=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsDQFFKDSnFr"
      },
      "outputs": [],
      "source": [
        "# ndarray data\n",
        "\n",
        "plt.plot(df['Adj Close'].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux-VzzFdSnFr"
      },
      "source": [
        "일자별 종가, 거래량 그래프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW7HRn68SnFr"
      },
      "outputs": [],
      "source": [
        "df.plot(x='Date', y=['Adj Close', 'Volume'], logy=True, rot=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHgehbwmSnFs"
      },
      "source": [
        "MinMax scaler 를 적용해서 종가/거래량 그래프를 그리면 2 변수의 추이를 보다 감각적으로 알 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTajzw_GSnFs"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "tmp = scaler.fit_transform(df[['Adj Close', 'Volume']])\n",
        "tmp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwoSQsplSnFs"
      },
      "source": [
        "MinMax scaler 를 적용한 종가/거래량 데이터를 DataFrame 에 추가해 작업도 가능..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff-sc6k5SnFt"
      },
      "outputs": [],
      "source": [
        "_ = pd.DataFrame(tmp, index=df['Date'], columns=['Adj Close', 'Volume'])\n",
        "_.plot(rot=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wwoulPMSnFt"
      },
      "outputs": [],
      "source": [
        "# ndarray 와 date index\n",
        "plt.plot(df['Date'], tmp)      #다변수\n",
        "plt.legend(['Close','Volume'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVQpQJXCSnFt"
      },
      "source": [
        "seaborn 을 사용한 종가 그래프"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxizUhD5SnFt"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.lineplot(data=df, x='Date', y='Adj Close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX8pwkpSSnFu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_QEgRZtSnFu",
        "tags": []
      },
      "source": [
        "## 훈련/검증 세트 분리\n",
        "\n",
        "시계열 데이터의 데이터셋은 보통 window_size라고 정의한다. window_size는 과거 기간의 주가 데이터에 기반하여 다음날의 종가를 예측할 것인가를 정하는 parameter이다. 과거 20일을 기반으로 내일 데이터를 예측한다라고 가정하면 window_size=20이다.\n",
        "\n",
        "실제 100일의 과거 데이터를 기반으로 데이터셋을 분리하도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-1M-6QxSnFu"
      },
      "outputs": [],
      "source": [
        "data = df[['Open','High','Low','Volume','Adj Close']].copy()\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgo3eEKUSnFu"
      },
      "source": [
        "스케일러의 시차가 1일(lag 1)인 입력 피쳐를 구축해 보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mEhczILSnFu"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()#feature_range = (0, 1))\n",
        "data_scaled = scaler.fit_transform(data)\n",
        "data_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoN-VQIqSnFv"
      },
      "outputs": [],
      "source": [
        "SPLIT_RATE = int(df.shape[0] * .7)\n",
        "WINDOW_SIZE = 60 # 시계열 주기."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNjfcsDuSnFv"
      },
      "outputs": [],
      "source": [
        "data_scaled[:SPLIT_RATE].shape, data_scaled[SPLIT_RATE:].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om9N0AeWSnFv"
      },
      "outputs": [],
      "source": [
        "train_scaled = data_scaled[:SPLIT_RATE]\n",
        "test_scaled = data_scaled[SPLIT_RATE:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkMmQQUfSnFv",
        "jupyter": {
          "source_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# def make_dataset(data:np.array, label, window=20):\n",
        "#     X, y = [], []\n",
        "    \n",
        "#     for i in range(len(data) - window_size):\n",
        "#         X.append(np.array(data[i:i+window_size]))\n",
        "#         y.append(np.array(label[i+window_size]))\n",
        "#     return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2nxnhUOSnFv"
      },
      "outputs": [],
      "source": [
        "def make_dataset(data:np.array, label, window=20):\n",
        "    '''시계열 ndarray 로 전달된 data와 label 데이터를 window 만큼 간격으로 분리해 준다.\n",
        "    결과는 (samples, steps, 1d) 형태로 반환한다.\n",
        "    '''\n",
        "\n",
        "    start_ = len(data)\n",
        "    X = [data[i:i+window] for i in range(start_ - window)]\n",
        "    y = [label[i+window] for i in range(start_ - window)]\n",
        "    \n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9ZmUrA5SnFw"
      },
      "outputs": [],
      "source": [
        "train_set = train_scaled[:,:-1]\n",
        "train_label = train_scaled[:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8lwabYDSnFw"
      },
      "outputs": [],
      "source": [
        "train_set.shape, train_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMlMKIR7SnFw"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = make_dataset(train_set, train_label, WINDOW_SIZE)\n",
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP6UEzKGSnFw"
      },
      "outputs": [],
      "source": [
        "test_set = test_scaled[:,:-1]\n",
        "test_label = test_scaled[:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGQyUDbDSnFx"
      },
      "outputs": [],
      "source": [
        "test_set.shape, test_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwClInVBSnFx"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = make_dataset(test_set, test_label, WINDOW_SIZE)\n",
        "X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pu_arahySnFx"
      },
      "outputs": [],
      "source": [
        "# 윈도우 사이즈 원본 데이터와 훈련/검증 세트의 차이\n",
        "X_train.shape[0] + X_test.shape[0], data_scaled.shape[0] - (X_train.shape[0] + X_test.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw5hFJ7bSnFx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8IE14bbSnFy"
      },
      "outputs": [],
      "source": [
        "INPUT = X_train.shape[2]\n",
        "INPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhQ5J4DLYY3H"
      },
      "source": [
        "# RNN 학습\n",
        "\n",
        "1. simple rnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXSyH7QfbWAN"
      },
      "source": [
        "## SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv2lSdr1aEz4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model1 = keras.Sequential()\n",
        "model1.add(keras.layers.SimpleRNN(units=30, return_sequences=True, input_shape=(WINDOW_SIZE, INPUT)))\n",
        "model1.add(keras.layers.SimpleRNN(30, activation='relu'))\n",
        "model1.add(keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 학습과정 설정 \n",
        "# model1.compile(optimizer=RMSprop(), loss='mae')\n",
        "model1.compile(loss='mse', optimizer=RMSprop(), metrics=['mae'])\n"
      ],
      "metadata": {
        "id": "zn6Ope7fu0hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuCv2aEmYdVT"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "history = model1.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2gPLaNHcDi2"
      },
      "outputs": [],
      "source": [
        "# LSTM 네트워크 학습 결과 확인\n",
        "plt.title('RNN:LSTM')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73m1aq5AderU"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Adam\n",
        "model1.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "history = model1.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxlTFcZIfC40"
      },
      "outputs": [],
      "source": [
        "# LSTM 네트워크 학습 결과 확인\n",
        "plt.title('RNN:LSTM-adam')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4fxICksdVY2"
      },
      "source": [
        "## GRU 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RApAJ5ufdYZX"
      },
      "outputs": [],
      "source": [
        "model_gru = keras.Sequential()\n",
        "model_gru.add(keras.layers.GRU(32, input_shape=(WINDOW_SIZE, INPUT)))\n",
        "model_gru.add(keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dErDFJD7d8Uc"
      },
      "outputs": [],
      "source": [
        "model_gru.compile(loss='mse', optimizer=RMSprop(), metrics=['mae'])\n",
        "\n",
        "history = model_gru.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=0,\n",
        "                     callbacks=[TqdmCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-_WswuLeB6e"
      },
      "outputs": [],
      "source": [
        "# GRU 학습 결과 확인\n",
        "plt.title('RNN::GRU')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VC39f5MjevNW"
      },
      "source": [
        "## GRU에 드롭아웃 사용\n",
        "\n",
        "훈련 손실과 검증 손실 곡선을 보면 모델이 과대적합인지 알 수 있다. 몇 번의 에포크 이후에 훈련 손실과 검증 손실이 현저하게 벌어지기 시작해서 이런 현상을 해결하기 위해 잘 알려진 드롭아웃을 적용해 보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBp8YiQ2gaMQ"
      },
      "outputs": [],
      "source": [
        "gru_dr = keras.Sequential()\n",
        "gru_dr.add( keras.layers.GRU(32,\n",
        "                              dropout=0.2,    # cuDNN을 사용할 수 없기 때문에\n",
        "                              recurrent_dropout=0.2,\n",
        "                              input_shape=(WINDOW_SIZE, INPUT)))\n",
        "gru_dr.add(keras.layers.Dense(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH8dHHEhgs9t"
      },
      "outputs": [],
      "source": [
        "model_gru.compile(loss='mse', optimizer=RMSprop(), metrics=['mae'])\n",
        "\n",
        "history = model_gru.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     steps_per_epoch=500,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=0,\n",
        "                     callbacks=[TqdmCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKSDBPVIhIQ_"
      },
      "outputs": [],
      "source": [
        "# GRU 학습 결과 확인\n",
        "plt.title('RNN::GRU DROPOUT')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07-c9uOZSnFx",
        "tags": []
      },
      "source": [
        "# Stacking RNN\n",
        "\n",
        "1. GRU Stacking\n",
        "1. LSTM Stacking\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://miro.medium.com/max/994/1*27vV5Pit7XEwKHfi6s5Q1w.png'>\n",
        " - https://medium.com/geekculture/how-to-use-model-stacking-to-improve-machine-learning-predictions-d113278612d4"
      ],
      "metadata": {
        "id": "eyWM2XdQ2we1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j2gx9PEN2vNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVI8s7aIhlhh"
      },
      "source": [
        "## GRU Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9raGlP3hvbX"
      },
      "outputs": [],
      "source": [
        "gru_stack = keras.Sequential()\n",
        "gru_stack.add(keras.layers.GRU(32,\n",
        "                     dropout=0.1,  # cuDNN을 사용할 수 없기 때문에\n",
        "                     recurrent_dropout=0.5,\n",
        "                     return_sequences=True,\n",
        "                     input_shape=(WINDOW_SIZE, INPUT)))\n",
        "gru_stack.add(keras.layers.GRU(64,\n",
        "                     activation='relu',  # cuDNN을 사용할 수 없기 때문에\n",
        "                     dropout=0.1,\n",
        "                     recurrent_dropout=0.5\n",
        "                    ))\n",
        "gru_stack.add(keras.layers.Dense(1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-tNGwF9n2gu"
      },
      "outputs": [],
      "source": [
        "gru_stack.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoGf3gZqiT51"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "gru_stack.compile(loss='mse', optimizer=RMSprop(), metrics=['mae'])\n",
        "\n",
        "history = gru_stack.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqrWedK6ib8v"
      },
      "outputs": [],
      "source": [
        "# GRU 학습 결과 확인\n",
        "plt.title('RNN::GRU Stacking')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSPj436qibnd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dU2e8NHrSnFx"
      },
      "source": [
        "## LSTM Stacking\n",
        "\n",
        "우리는 50개의 뉴런과 4개의 숨겨진 층으로 LSTM을 만들 것이다. 마지막으로, 우리는 정규화된 주가를 예측하기 위해 출력층에 1개의 뉴런을 할당할 것이다. MSE 손실 함수와 Adam stochastic gradient decent optimizer를 사용할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6o1z24gWIe4B"
      },
      "outputs": [],
      "source": [
        "# 입력으로 7일간의 5가지 데이터(시가, 종가, 고가, 저가, 거래량)을 다룬다.\n",
        "lstmstack = keras.Sequential(name='LSTM1')\n",
        "#Adding the first LSTM layer and some Dropout regularisation\n",
        "lstmstack.add(keras.layers.LSTM(units = 50, return_sequences = True, input_shape = (WINDOW_SIZE, INPUT)))\n",
        "lstmstack.add(keras.layers.Dropout(0.2))\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "lstmstack.add(keras.layers.LSTM(units = 50, return_sequences = True))\n",
        "lstmstack.add(keras.layers.Dropout(0.2))\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "lstmstack.add(keras.layers.LSTM(units = 50, return_sequences = True))\n",
        "lstmstack.add(keras.layers.Dropout(0.2))\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "lstmstack.add(keras.layers.LSTM(units = 50))\n",
        "lstmstack.add(keras.layers.Dropout(0.2))\n",
        "# Adding the output layer\n",
        "lstmstack.add(keras.layers.Dense(units = 1))\n",
        "\n",
        "lstmstack.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnMHlfqhSnFy"
      },
      "source": [
        "학습 시작."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XavhYhX4Imax",
        "scrolled": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# 모델 학습과정 설정 \n",
        "lstmstack.compile(loss='mse', optimizer=RMSprop(), metrics=['mae'])\n",
        "\n",
        "history = lstmstack.fit(X_train, y_train, \n",
        "                     epochs=100,\n",
        "                     validation_split=0.2,\n",
        "                     verbose=0,\n",
        "                     callbacks=[TqdmCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJSlA-z7NRHE"
      },
      "outputs": [],
      "source": [
        "# LSTM 네트워크 학습 결과 확인\n",
        "plt.title('RNN:LSTM Stack')\n",
        "plt.plot(history.history['loss'], 'b-', label='loss')\n",
        "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqc23FJ2SnFz"
      },
      "outputs": [],
      "source": [
        "# 모델 테스트\n",
        "res = lstmstack.evaluate(X_test)\n",
        "print('loss:', res[0], ', mae:', res[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY4cR_KFSnFz"
      },
      "outputs": [],
      "source": [
        "# 예측\n",
        "predictions = lstmstack.predict(X_test)\n",
        "predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04EbtRLhSnFz"
      },
      "outputs": [],
      "source": [
        "y_test.shape, predictions.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXfYxuFmSnFz"
      },
      "outputs": [],
      "source": [
        "# Plot predictions\n",
        "plt.plot(y_test[:100], 'bo', label='testY')              # Draw testY\n",
        "plt.plot(predictions[:100], 'r', label='PredictY')    # Draw PredictY\n",
        "\n",
        "plt.xlabel(\"Time Period\")                   # axis x  labeling\n",
        "plt.ylabel(\"Stock Price\")                   # axis y  labeling\n",
        "\n",
        "plt.title('LSTM Stack: Stock Prediction')               # Graph Title\n",
        "plt.legend()                                # labeling for each graph\n",
        "plt.show()                                  # show for us"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKYNaujsSnF0"
      },
      "outputs": [],
      "source": [
        "# predicted_stock_price = scaler.inverse_transform(predictions)\n",
        "print( np.mean((predictions-y_test)**2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}